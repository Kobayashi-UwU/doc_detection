<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document Scanner with Camera and Real-time Detection</title>
    <link rel="stylesheet" href="https://pyscript.net/latest/pyscript.css">
    <script defer src="https://pyscript.net/latest/pyscript.js"></script>
    <script defer src="https://docs.opencv.org/4.x/opencv.js"></script>
</head>
<body>

<py-config type="toml">
packages = ["numpy", "opencv-python"]
</py-config>

<h1>Document Scanner</h1>

<!-- File input to upload an image -->
<input type="file" id="imageInput" accept="image/*">
<br><br>

<!-- Camera controls -->
<button id="startCamera">Start Camera</button>
<button id="stopCamera" style="display:none;">Stop Camera</button>
<br><br>

<!-- Video element for camera feed -->
<video id="video" width="640" height="480" style="display:none;"></video>

<!-- Canvas for displaying processed frames -->
<canvas id="outputCanvas" width="640" height="480" style="display:none;"></canvas>

<!-- Threshold sliders -->
<div>
    <label for="threshold1">Threshold 1: </label>
    <input type="range" id="threshold1" min="0" max="255" value="200">
    <span id="threshold1Value">200</span>
</div>
<div>
    <label for="threshold2">Threshold 2: </label>
    <input type="range" id="threshold2" min="0" max="255" value="200">
    <span id="threshold2Value">200</span>
</div>
<br>

<!-- Process button to trigger document scanning -->
<button id="processButton">Process Image</button>

<!-- Area to display the scanned document -->
<img id="outputImage" style="display:none;" alt="Scanned Document" />

<script>
let video = document.getElementById('video');
let canvas = document.getElementById('outputCanvas');
let ctx = canvas.getContext('2d');
let mediaStream = null;

document.getElementById('startCamera').addEventListener('click', async () => {
    try {
        mediaStream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = mediaStream;
        video.play();
        document.getElementById('startCamera').style.display = 'none';
        document.getElementById('stopCamera').style.display = 'inline-block';
        video.style.display = 'block';
        canvas.style.display = 'block';
        document.getElementById('outputImage').style.display = 'none';
        startVideoProcessing();
    } catch (err) {
        console.error("Error accessing the camera:", err);
    }
});

document.getElementById('stopCamera').addEventListener('click', () => {
    if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop());
        video.srcObject = null;
        document.getElementById('startCamera').style.display = 'inline-block';
        document.getElementById('stopCamera').style.display = 'none';
        video.style.display = 'none';
        canvas.style.display = 'none';
    }
});

function startVideoProcessing() {
    if (video.paused || video.ended) return;
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
    let imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    processFrame(imageData);
    requestAnimationFrame(startVideoProcessing);
}

function processFrame(imageData) {
    // This function will be implemented in PyScript
    if (typeof window.pyodide !== 'undefined') {
        window.pyodide.runPython(`
            process_frame(${JSON.stringify(Array.from(imageData.data))}, ${imageData.width}, ${imageData.height})
        `);
    }
}
</script>

<py-script>
import cv2
import numpy as np
from js import document, FileReader, ImageData
from pyodide.ffi import create_proxy
import base64

# Util functions (from your Utlis.py)
def stackImages(imgArray, scale, labels=[]):
    rows = len(imgArray)
    cols = len(imgArray[0])
    rowsAvailable = isinstance(imgArray[0], list)
    width = imgArray[0][0].shape[1]
    height = imgArray[0][0].shape[0]
    if rowsAvailable:
        for x in range(0, rows):
            for y in range(0, cols):
                imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)
                if len(imgArray[x][y].shape) == 2:
                    imgArray[x][y] = cv2.cvtColor(imgArray[x][y], cv2.COLOR_GRAY2BGR)
        hor = [np.zeros((height, width, 3), np.uint8)] * rows
        for x in range(0, rows):
            hor[x] = np.hstack(imgArray[x])
        ver = np.vstack(hor)
    else:
        for x in range(0, rows):
            imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)
            if len(imgArray[x].shape) == 2:
                imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)
        ver = np.hstack(imgArray)
    return ver

def biggestContour(contours):
    biggest = np.array([])
    max_area = 0
    for i in contours:
        area = cv2.contourArea(i)
        if area > 5000:
            peri = cv2.arcLength(i, True)
            approx = cv2.approxPolyDP(i, 0.02 * peri, True)
            if area > max_area and len(approx) == 4:
                biggest = approx
                max_area = area
    return biggest, max_area

def reorder(points):
    points = points.reshape((4, 2))
    new_points = np.zeros((4, 1, 2), dtype=np.int32)
    add = points.sum(1)
    new_points[0] = points[np.argmin(add)]
    new_points[3] = points[np.argmax(add)]
    diff = np.diff(points, axis=1)
    new_points[1] = points[np.argmin(diff)]
    new_points[2] = points[np.argmax(diff)]
    return new_points

# Processing logic for uploaded image
def onProcessClick(event):
    image_input = document.getElementById("imageInput")
    file = image_input.files.item(0)
    
    if not file:
        print("No image uploaded")
        return
    
    reader = FileReader.new()
    
    def onload(event):
        data_url = reader.result
        base64_data = data_url.split(",")[1]
        img_data = np.frombuffer(bytearray(base64.b64decode(base64_data)), dtype=np.uint8)
        img = cv2.imdecode(img_data, cv2.IMREAD_COLOR)
        
        process_image(img)
    
    reader.onload = create_proxy(onload)
    reader.readAsDataURL(file)

def process_image(img):
    # Get threshold values from sliders
    threshold1 = int(document.getElementById("threshold1").value)
    threshold2 = int(document.getElementById("threshold2").value)
    
    # Image processing pipeline from your Main.py
    heightImg, widthImg = 640, 480
    img = cv2.resize(img, (widthImg, heightImg))
    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    imgBlur = cv2.GaussianBlur(imgGray, (5, 5), 1)
    imgThreshold = cv2.Canny(imgBlur, threshold1, threshold2)
    kernel = np.ones((5, 5))
    imgDial = cv2.dilate(imgThreshold, kernel, iterations=2)
    imgThreshold = cv2.erode(imgDial, kernel, iterations=1)

    contours, _ = cv2.findContours(imgThreshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    biggest, _ = biggestContour(contours)
    
    if biggest.size != 0:
        biggest = reorder(biggest)
        pts1 = np.float32(biggest)
        pts2 = np.float32([[0, 0], [widthImg, 0], [0, heightImg], [widthImg, heightImg]])
        matrix = cv2.getPerspectiveTransform(pts1, pts2)
        imgWarpColored = cv2.warpPerspective(img, matrix, (widthImg, heightImg))
        
        imgWarpGray = cv2.cvtColor(imgWarpColored, cv2.COLOR_BGR2GRAY)
        imgAdaptiveThre = cv2.adaptiveThreshold(imgWarpGray, 255, 1, 1, 7, 2)
        imgAdaptiveThre = cv2.bitwise_not(imgAdaptiveThre)
        imgAdaptiveThre = cv2.medianBlur(imgAdaptiveThre, 3)
        
        stackedImage = stackImages([[img, imgGray, imgThreshold], [imgWarpColored, imgWarpGray, imgAdaptiveThre]], 0.75)
        
        _, img_encoded = cv2.imencode('.png', stackedImage)
        img_base64 = base64.b64encode(img_encoded).decode('utf-8')
        output_image = document.getElementById("outputImage")
        output_image.src = f"data:image/png;base64,{img_base64}"
        output_image.style.display = "block"
    else:
        print("No document detected")

# Update threshold values on slider change
def updateThreshold1(event):
    document.getElementById("threshold1Value").innerText = event.target.value

def updateThreshold2(event):
    document.getElementById("threshold2Value").innerText = event.target.value

# Process frame from camera
def process_frame(frame_data, width, height):
    # Convert frame data to numpy array
    frame = np.array(frame_data, dtype=np.uint8).reshape((height, width, 4))
    
    # Convert RGBA to BGR
    frame = cv2.cvtColor(frame, cv2.COLOR_RGBA2BGR)
    
    # Process the frame
    process_image(frame)

process_click_proxy = create_proxy(onProcessClick)
document.getElementById("processButton").addEventListener("click", process_click_proxy)

# Add event listeners to sliders for updating threshold values
threshold1_proxy = create_proxy(updateThreshold1)
threshold2_proxy = create_proxy(updateThreshold2)
document.getElementById("threshold1").addEventListener("input", threshold1_proxy)
document.getElementById("threshold2").addEventListener("input", threshold2_proxy)

</py-script>

</body>
</html>